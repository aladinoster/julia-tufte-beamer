\begin{frame}[fragile]{POMDPs and Beliefs}

\begin{itemize}
    \item A POMDP\footnote{Partially observable Markov decision process. ``Partially observable'' is key in understanding beliefs.} is an MDP with \textit{state uncertainty}
    \begin{align*}
        \text{MDP: }& \langle \mathcal{S},\, \mathcal{A},\, T,\, R,\, \gamma \rangle\\
        \text{POMDP: }& \langle \mathcal{S},\, \mathcal{A},\, {\color{darkblue}\mathcal{O}},\, T,\, R,\, {\color{darkblue}O},\, \gamma \rangle
    \end{align*}
    \item The agent receives an \textit{observation} of the current state rather than the true state (potentially imperfect observations)
    \item Using past observations, the agent builds a \textit{belief} of their underlying state
    \begin{itemize}
        \item Which can be represented by a probability distribution over true states
    \end{itemize}
    \item Remember, a POMDP is a \textit{problem formulation} and not an \textit{algorithm}
    \begin{itemize}
        \item A POMDP formulation enables the use of solution methods, i.e. algorithms.
    \end{itemize}
\end{itemize}

\end{frame}